{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb04893-d893-419c-bfd0-8bd330eacc36",
   "metadata": {},
   "source": [
    "# **AI Python For Beginners**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5231f3-101c-4218-95c2-0f303e7c16bc",
   "metadata": {},
   "source": [
    "## **Lesson 3: Navigate the learning platform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ab7063-d47d-42ee-b6c3-8692ebda1e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World :)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3075f603-4580-4fd8-a237-d3c15a3eaba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 292 days betweem christmas and my birthday\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "christmas = datetime(year=2024,month=12,day=25)\n",
    "birthday = datetime(year=2025,month=10,day=13)\n",
    "delta = birthday-christmas\n",
    "print(f\"there are {delta.days} days betweem christmas and my birthday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c4a36",
   "metadata": {},
   "source": [
    "# **Multi-line f-string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43ff73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Most countries use the metric system por recipe measurment,\n",
      "        but American bakers use a different system. For example, they se fluid\n",
      "        ounces to measure liquits insted of milliliters(ml).\n",
      "        So you need to convert recipe units to your local measuring system!\n",
      "        For example. 8 fluid ounces of mild is 236.588 ml.\n",
      "        And 100 ml of water is 3.381405650328842 fluid ounces.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "        Most countries use the metric system por recipe measurment,\n",
    "        but American bakers use a different system. For example, they se fluid\n",
    "        ounces to measure liquits insted of milliliters(ml).\n",
    "        So you need to convert recipe units to your local measuring system!\n",
    "        For example. 8 fluid ounces of mild is {8*29.5735} ml.\n",
    "        And 100 ml of water is {100/29.5735} fluid ounces.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd48ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import print_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0285551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# @title test.py\n",
    "%%writefile test.py\n",
    "import sys\n",
    "print(sys.argv)\n",
    "print(\"Hola, mi nombre es\", sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335928ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"helper_functions.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "def print_llm_response(response):\n",
    "    if isinstance(response, dict) and \"choices\" in response:\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    elif isinstance(response, str):\n",
    "        print(response)\n",
    "    else:\n",
    "        print(response)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cfce46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahora funciona en Jupyter Desktop ðŸš€\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import print_llm_response\n",
    "print_llm_response(\"Ahora funciona en Jupyter Desktop ðŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fcccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "number_of_lines=5\n",
    "# prompt\n",
    "prompt = f\"\"\"Write a comedy story in {number_of_lines} lines\"\"\"\n",
    "#response\n",
    "response = get_llm_response(prompt)\n",
    "# respuesta\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ee65083",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_llm_response' from 'helper_functions' (C:\\Users\\soporte\\Documents\\DEEPLEARNING_AI\\AI_PYTHON\\helper_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_llm_response,get_llm_response\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_llm_response' from 'helper_functions' (C:\\Users\\soporte\\Documents\\DEEPLEARNING_AI\\AI_PYTHON\\helper_functions.py)"
     ]
    }
   ],
   "source": [
    "from helper_functions import print_llm_response,get_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97ed75d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a four line birthday poem for my frined Daniel.\n",
      "The poem should be inspired by the first letter of my friend's name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Daniel\"\n",
    "prompt=f\"\"\"\n",
    "Write a four line birthday poem for my frined {name}.\n",
    "The poem should be inspired by the first letter of my friend's name.\n",
    "\"\"\"\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ef31c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_task=[\n",
    "    \"Compose a brief email to my boss\",\n",
    "    \"Write a birthday poerm for Otto\",\n",
    "    \"Write a 300-word review of the movil 'The Arrival'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "446d37ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose a brief email to my boss\n"
     ]
    }
   ],
   "source": [
    "task = list_of_task[0]\n",
    "print_llm_response(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cedd7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ice cream flavor example\n",
    "ice_cream_flavors=[\n",
    "    \"Vanilla\",\n",
    "    \"Chocolate\",\n",
    "    \"Strawberry\",\n",
    "    \"Mint Chocolate Chip\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2ce1961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Vanilla\n",
      "    \n",
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Chocolate\n",
      "    \n",
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Strawberry\n",
      "    \n",
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Mint Chocolate Chip\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for flavor in ice_cream_flavors:\n",
    "    prompt=f\"\"\"For the ice cream flavor listed below, \n",
    "    provide a captivating description thtat could be used for promotion\n",
    "    Flavor: {flavor}\n",
    "    \"\"\"\n",
    "    print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6465970f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_llm_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m ice_cream_flavors:\n\u001b[0;32m      3\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFor the ice cream flavor listed bellow,\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    provide a captivating description that could be used for promotion\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m    Flavor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflavor\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     description\u001b[38;5;241m=\u001b[39m get_llm_response(prompt)\n\u001b[0;32m      8\u001b[0m     promotional_description\u001b[38;5;241m.\u001b[39mappend(description)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_llm_response' is not defined"
     ]
    }
   ],
   "source": [
    "promotonal_descriptions=[]\n",
    "for flavor in ice_cream_flavors:\n",
    "    prompt=f\"\"\"For the ice cream flavor listed bellow,\n",
    "    provide a captivating description that could be used for promotion\n",
    "    Flavor: {flavor}\n",
    "    \"\"\"\n",
    "    description= get_llm_response(prompt)\n",
    "    promotional_description.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77d2b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task example, large list not ordered by priority. Want to prioritize\n",
    "list_of_tasks = [\n",
    "    \"Compose a brief email to my boss explaining that I will be late for tomorrow's meeting.\",\n",
    "    \"Write a birthday poem for Otto, celebrating his 28th birthday.\",\n",
    "    \"Write a 300-word review of the movie 'The Arrival'.\",\n",
    "    \"Draft a thank-you note for my neighbor Dapinder who helped water my plants while I was on vacation.\",\n",
    "    \"Create an outline for a presentation on the benefits of remote work.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979269fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of that unorganized large list, divide tasks by priority\n",
    "high_priority_tasks = [\n",
    "    \"Compose a brief email to my boss explaining that I will be late for tomorrow's meeting.\",\n",
    "    \"Create an outline for a presentation on the benefits of remote work.\"\n",
    "]\n",
    "\n",
    "medium_priority_tasks = [\n",
    "    \"Write a birthday poem for Otto, celebrating his 28th birthday.\",\n",
    "    \"Draft a thank-you note for my neighbor Dapinder who helped water my plants while I was on vacation.\"\n",
    "]\n",
    "\n",
    "low_priority_tasks = [\n",
    "    \"Write a 300-word review of the movie 'The Arrival'.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6efd48f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary with all tasks\n",
    "#dictionaries can contain lists!\n",
    "prioritized_tasks = {\n",
    "    \"high_priority\": high_priority_tasks,\n",
    "    \"medium_priority\": medium_priority_tasks,\n",
    "    \"low_priority\": low_priority_tasks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba572dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete high priority tasks \n",
    "for task in prioritized_tasks[\"high_priority\"]:\n",
    "    print_llm_response(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6b74b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_preferences_tommy = {\n",
    "        \"dietary_restrictions\": \"vegetarian\",\n",
    "        \"favorite_ingredients\": [\"tofu\", \"olives\"],\n",
    "        \"experience_level\": \"intermediate\",\n",
    "        \"maximum_spice_level\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c958a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Please suggest a recipe that tries to include \n",
    "the following ingredients: \n",
    "{food_preferences_tommy[\"favorite_ingredients\"]}.\n",
    "The recipe should adhere to the following dietary restrictions:\n",
    "{food_preferences_tommy[\"dietary_restrictions\"]}.\n",
    "The difficulty of the recipe should be: \n",
    "{food_preferences_tommy[\"experience_level\"]}\n",
    "The maximum spice level on a scale of 10 should be: \n",
    "{food_preferences_tommy[\"maximum_spice_level\"]} \n",
    "Provide a two sentence description.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "898a04be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import print_llm_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e8f12f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list=[\n",
    "    {\"description\":\"a\",\n",
    "    \"time_to_complete\":3\n",
    "    },\n",
    "    {\"description\":\"b\",\n",
    "    \"time_to_complete\":60\n",
    "    },\n",
    "    {\"description\":\"c\",\n",
    "    \"time_to_complete\":30\n",
    "    },\n",
    "    {\"description\":\"d\",\n",
    "    \"time_to_complete\":5\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "311caee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'a', 'time_to_complete': 3}\n"
     ]
    }
   ],
   "source": [
    "task= task_list[0]\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aa708ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62e6b1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task_list[1]\n",
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5519cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task_list[2]\n",
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5442a74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "task = task_list[3]\n",
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9054fee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "for task in task_list:\n",
    "    if task[\"time_to_complete\"]<=5:\n",
    "        task_to_do=task[\"description\"]\n",
    "        print_llm_response(task_to_do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48db087a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>:\n",
    "    <br><br>\n",
    "    Explain this code line by line:\n",
    "    <br><br>f = open(\"email.txt\", \"r\")\n",
    "    <br>email = f.read()\n",
    "    <br>f.close()\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544cd8a",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>:\n",
    "    <br><br>\n",
    "    What happens if I don't close a file?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836301f2",
   "metadata": {},
   "source": [
    "## USING LLMs to extract bullet point from email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d908cb0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_llm_response' from 'helper_functions' (C:\\Users\\soporte\\Documents\\DEEPLEARNING_AI\\AI_PYTHON\\helper_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_llm_response\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, Markdown\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_llm_response' from 'helper_functions' (C:\\Users\\soporte\\Documents\\DEEPLEARNING_AI\\AI_PYTHON\\helper_functions.py)"
     ]
    }
   ],
   "source": [
    "from helper_functions import get_llm_response\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d577ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"email.txt\", \"r\")\n",
    "email = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35670688",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Extract bullet points from the following email. \n",
    "Include the sender information. \n",
    "\n",
    "Email:\n",
    "{email}\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe65bd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bullet_points = get_llm_response(prompt)\n",
    "print(bullet_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d092edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print in Markdown format\n",
    "display(Markdown(bullet_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a3ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # TRY CHANGING THIS PROMPT TO ASK DIFFERENT QUESTIONS\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes restaurants and food dishes. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e067411",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
