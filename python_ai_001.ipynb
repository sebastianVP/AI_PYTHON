{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cb04893-d893-419c-bfd0-8bd330eacc36",
   "metadata": {},
   "source": [
    "# **AI Python For Beginners**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5231f3-101c-4218-95c2-0f303e7c16bc",
   "metadata": {},
   "source": [
    "## **Lesson 3: Navigate the learning platform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ab7063-d47d-42ee-b6c3-8692ebda1e9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World :)\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello World :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3075f603-4580-4fd8-a237-d3c15a3eaba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 292 days betweem christmas and my birthday\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "christmas = datetime(year=2024,month=12,day=25)\n",
    "birthday = datetime(year=2025,month=10,day=13)\n",
    "delta = birthday-christmas\n",
    "print(f\"there are {delta.days} days betweem christmas and my birthday\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795c4a36",
   "metadata": {},
   "source": [
    "# **Multi-line f-string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b43ff73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Most countries use the metric system por recipe measurment,\n",
      "        but American bakers use a different system. For example, they se fluid\n",
      "        ounces to measure liquits insted of milliliters(ml).\n",
      "        So you need to convert recipe units to your local measuring system!\n",
      "        For example. 8 fluid ounces of mild is 236.588 ml.\n",
      "        And 100 ml of water is 3.381405650328842 fluid ounces.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "        Most countries use the metric system por recipe measurment,\n",
    "        but American bakers use a different system. For example, they se fluid\n",
    "        ounces to measure liquits insted of milliliters(ml).\n",
    "        So you need to convert recipe units to your local measuring system!\n",
    "        For example. 8 fluid ounces of mild is {8*29.5735} ml.\n",
    "        And 100 ml of water is {100/29.5735} fluid ounces.\n",
    "\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd48ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import print_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0285551",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# @title test.py\n",
    "%%writefile test.py\n",
    "import sys\n",
    "print(sys.argv)\n",
    "print(\"Hola, mi nombre es\", sys.argv[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "335928ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"helper_functions.py\", \"w\") as f:\n",
    "    f.write(\"\"\"\n",
    "def print_llm_response(response):\n",
    "    if isinstance(response, dict) and \"choices\" in response:\n",
    "        print(response[\"choices\"][0][\"message\"][\"content\"])\n",
    "    elif isinstance(response, str):\n",
    "        print(response)\n",
    "    else:\n",
    "        print(response)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cfce46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ahora funciona en Jupyter Desktop ðŸš€\n"
     ]
    }
   ],
   "source": [
    "from helper_functions import print_llm_response\n",
    "print_llm_response(\"Ahora funciona en Jupyter Desktop ðŸš€\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6fcccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#variables\n",
    "number_of_lines=5\n",
    "# prompt\n",
    "prompt = f\"\"\"Write a comedy story in {number_of_lines} lines\"\"\"\n",
    "#response\n",
    "response = get_llm_response(prompt)\n",
    "# respuesta\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af36f03d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_llm_response' from 'helper_functions' (C:\\Users\\soporte\\Documents\\DEEPLEARNING_AI\\AI_PYTHON\\helper_functions.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_llm_response,get_llm_response\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'get_llm_response' from 'helper_functions' (C:\\Users\\soporte\\Documents\\DEEPLEARNING_AI\\AI_PYTHON\\helper_functions.py)"
     ]
    }
   ],
   "source": [
    "from helper_functions import print_llm_response,get_llm_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cf8f21e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Write a four line birthday poem for my frined Daniel.\n",
      "The poem should be inspired by the first letter of my friend's name.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "name = \"Daniel\"\n",
    "prompt=f\"\"\"\n",
    "Write a four line birthday poem for my frined {name}.\n",
    "The poem should be inspired by the first letter of my friend's name.\n",
    "\"\"\"\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ad9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_task=[\n",
    "    \"Compose a brief email to my boss\",\n",
    "    \"Write a birthday poerm for Otto\",\n",
    "    \"Write a 300-word review of the movil 'The Arrival'\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22f57ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose a brief email to my boss\n"
     ]
    }
   ],
   "source": [
    "task = list_of_task[0]\n",
    "print_llm_response(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39ca04de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ice cream flavor example\n",
    "ice_cream_flavors=[\n",
    "    \"Vanilla\",\n",
    "    \"Chocolate\",\n",
    "    \"Strawberry\",\n",
    "    \"Mint Chocolate Chip\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "415a0a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Vanilla\n",
      "    \n",
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Chocolate\n",
      "    \n",
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Strawberry\n",
      "    \n",
      "For the ice cream flavor listed below, \n",
      "    provide a captivating description thtat could be used for promotion\n",
      "    Flavor: Mint Chocolate Chip\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "for flavor in ice_cream_flavors:\n",
    "    prompt=f\"\"\"For the ice cream flavor listed below, \n",
    "    provide a captivating description thtat could be used for promotion\n",
    "    Flavor: {flavor}\n",
    "    \"\"\"\n",
    "    print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d900a545",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_llm_response' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 7\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m flavor \u001b[38;5;129;01min\u001b[39;00m ice_cream_flavors:\n\u001b[0;32m      3\u001b[0m     prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mFor the ice cream flavor listed bellow,\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    provide a captivating description that could be used for promotion\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m    Flavor: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflavor\u001b[38;5;132;01m}\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 7\u001b[0m     description\u001b[38;5;241m=\u001b[39m get_llm_response(prompt)\n\u001b[0;32m      8\u001b[0m     promotional_description\u001b[38;5;241m.\u001b[39mappend(description)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_llm_response' is not defined"
     ]
    }
   ],
   "source": [
    "promotonal_descriptions=[]\n",
    "for flavor in ice_cream_flavors:\n",
    "    prompt=f\"\"\"For the ice cream flavor listed bellow,\n",
    "    provide a captivating description that could be used for promotion\n",
    "    Flavor: {flavor}\n",
    "    \"\"\"\n",
    "    description= get_llm_response(prompt)\n",
    "    promotional_description.append(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ea96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task example, large list not ordered by priority. Want to prioritize\n",
    "list_of_tasks = [\n",
    "    \"Compose a brief email to my boss explaining that I will be late for tomorrow's meeting.\",\n",
    "    \"Write a birthday poem for Otto, celebrating his 28th birthday.\",\n",
    "    \"Write a 300-word review of the movie 'The Arrival'.\",\n",
    "    \"Draft a thank-you note for my neighbor Dapinder who helped water my plants while I was on vacation.\",\n",
    "    \"Create an outline for a presentation on the benefits of remote work.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fc464423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instead of that unorganized large list, divide tasks by priority\n",
    "high_priority_tasks = [\n",
    "    \"Compose a brief email to my boss explaining that I will be late for tomorrow's meeting.\",\n",
    "    \"Create an outline for a presentation on the benefits of remote work.\"\n",
    "]\n",
    "\n",
    "medium_priority_tasks = [\n",
    "    \"Write a birthday poem for Otto, celebrating his 28th birthday.\",\n",
    "    \"Draft a thank-you note for my neighbor Dapinder who helped water my plants while I was on vacation.\"\n",
    "]\n",
    "\n",
    "low_priority_tasks = [\n",
    "    \"Write a 300-word review of the movie 'The Arrival'.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecfb5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary with all tasks\n",
    "#dictionaries can contain lists!\n",
    "prioritized_tasks = {\n",
    "    \"high_priority\": high_priority_tasks,\n",
    "    \"medium_priority\": medium_priority_tasks,\n",
    "    \"low_priority\": low_priority_tasks\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e8807b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete high priority tasks \n",
    "for task in prioritized_tasks[\"high_priority\"]:\n",
    "    print_llm_response(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da29a9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "food_preferences_tommy = {\n",
    "        \"dietary_restrictions\": \"vegetarian\",\n",
    "        \"favorite_ingredients\": [\"tofu\", \"olives\"],\n",
    "        \"experience_level\": \"intermediate\",\n",
    "        \"maximum_spice_level\": 6\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d736d8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Please suggest a recipe that tries to include \n",
    "the following ingredients: \n",
    "{food_preferences_tommy[\"favorite_ingredients\"]}.\n",
    "The recipe should adhere to the following dietary restrictions:\n",
    "{food_preferences_tommy[\"dietary_restrictions\"]}.\n",
    "The difficulty of the recipe should be: \n",
    "{food_preferences_tommy[\"experience_level\"]}\n",
    "The maximum spice level on a scale of 10 should be: \n",
    "{food_preferences_tommy[\"maximum_spice_level\"]} \n",
    "Provide a two sentence description.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a585046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import print_llm_response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4479678",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_list=[\n",
    "    {\"description\":\"a\",\n",
    "    \"time_to_complete\":3\n",
    "    },\n",
    "    {\"description\":\"b\",\n",
    "    \"time_to_complete\":60\n",
    "    },\n",
    "    {\"description\":\"c\",\n",
    "    \"time_to_complete\":30\n",
    "    },\n",
    "    {\"description\":\"d\",\n",
    "    \"time_to_complete\":5\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "506d7a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'description': 'a', 'time_to_complete': 3}\n"
     ]
    }
   ],
   "source": [
    "task= task_list[0]\n",
    "print(task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7e1048ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n"
     ]
    }
   ],
   "source": [
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0e437764",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task_list[1]\n",
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7609f6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = task_list[2]\n",
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e2d248a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d\n"
     ]
    }
   ],
   "source": [
    "task = task_list[3]\n",
    "if task[\"time_to_complete\"]<=5:\n",
    "    task_to_do = task[\"description\"]\n",
    "    print_llm_response(task_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4a55049a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a\n",
      "d\n"
     ]
    }
   ],
   "source": [
    "for task in task_list:\n",
    "    if task[\"time_to_complete\"]<=5:\n",
    "        task_to_do=task[\"description\"]\n",
    "        print_llm_response(task_to_do)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43756d4e",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>:\n",
    "    <br><br>\n",
    "    Explain this code line by line:\n",
    "    <br><br>f = open(\"email.txt\", \"r\")\n",
    "    <br>email = f.read()\n",
    "    <br>f.close()\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f52448",
   "metadata": {},
   "source": [
    "<p style=\"background-color:#F5C780; padding:15px\"> ðŸ¤– <b>Use the Chatbot</b>:\n",
    "    <br><br>\n",
    "    What happens if I don't close a file?\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd1c4c",
   "metadata": {},
   "source": [
    "## USING LLMs to extract bullet point from email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afacf6e6",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOpenAIError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mhelper_functions_original\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_journal\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mIPython\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdisplay\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m display, Markdown\n",
      "File \u001b[1;32m~\\Documents\\DEEPLEARNING_AI\\AI_PYTHON\\helper_functions_original.py:16\u001b[0m\n\u001b[0;32m     13\u001b[0m openai_api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Set up the OpenAI client\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(api_key\u001b[38;5;241m=\u001b[39mopenai_api_key)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_csv_dict\u001b[39m(csv_file_path):\n\u001b[0;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This function takes a csv file and loads it as a dict.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_client.py:135\u001b[0m, in \u001b[0;36mOpenAI.__init__\u001b[1;34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[0m\n\u001b[0;32m    133\u001b[0m     api_key \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOPENAI_API_KEY\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 135\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[0;32m    136\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    137\u001b[0m     )\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mOpenAIError\u001b[0m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "from helper_functions_original import read_journal\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7e7b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"email.txt\", \"r\")\n",
    "email = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50129916",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"Extract bullet points from the following email. \n",
    "Include the sender information. \n",
    "\n",
    "Email:\n",
    "{email}\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98aca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bullet_points = get_llm_response(prompt)\n",
    "print(bullet_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89b754c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print in Markdown format\n",
    "display(Markdown(bullet_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08be4bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"cape_town.txt\", \"madrid.txt\", \"rio_de_janeiro.txt\", \n",
    "         \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    # Read journal file for the city\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "\n",
    "    # TRY CHANGING THIS PROMPT TO ASK DIFFERENT QUESTIONS\n",
    "    prompt = f\"\"\"Respond with \"Yes\" or \"No\": \n",
    "    the journal describes restaurants and food dishes. \n",
    "\n",
    "    Journal:\n",
    "    {journal}\"\"\"\n",
    "\n",
    "    # Use LLM to determine if the journal entry is useful\n",
    "    print(f\"{file} -> {get_llm_response(prompt)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "353d8c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import *\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "668352a5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'read_journal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m journal_rio_de_janeiro \u001b[38;5;241m=\u001b[39m read_journal(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrio_de_janeiro.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'read_journal' is not defined"
     ]
    }
   ],
   "source": [
    "journal_rio_de_janeiro = read_journal(\"rio_de_janeiro.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841f72de",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [\"cape_town.txt\", \"istanbul.txt\", \"new_york.txt\", \"paris.txt\", \n",
    "          \"rio_de_janeiro.txt\", \"sydney.txt\", \"tokyo.txt\"]\n",
    "\n",
    "for file in files:\n",
    "    #Open file and read contents\n",
    "    journal_entry = read_journal(file)\n",
    "\n",
    "    #Extract restaurants and display csv\n",
    "    prompt =  f\"\"\"Please extract a comprehensive list of the restaurants \n",
    "    and their respective best dishes mentioned in the following journal entry. \n",
    "    \n",
    "    Ensure that each restaurant name is accurately identified and listed. \n",
    "    Provide your answer in CSV format, ready to save.\n",
    "\n",
    "    Exclude the \"```csv\" declaration, don't add spaces after the \n",
    "    comma, include column headers.\n",
    "\n",
    "    Format:\n",
    "    Restaurant, Dish\n",
    "    Res_1, Dsh_1\n",
    "    ...\n",
    "\n",
    "    Journal entry:\n",
    "    {journal_entry}\n",
    "    \"\"\"\n",
    "    \n",
    "    print(file)\n",
    "    print_llm_response(prompt)\n",
    "    print(\"\") # Prints a blank line!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c660e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from helper_functions import get_llm_response, print_llm_response, display_table\n",
    "from IPython.display import Markdown\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bafe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"itinerary.csv\", 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4436558",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_reader = csv.DictReader(f)\n",
    "itinerary = []\n",
    "for row in csv_reader:\n",
    "    print(row)\n",
    "    itinerary.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "96e6c85a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m f\u001b[38;5;241m.\u001b[39mclose()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e742e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first destination from the itinerary list (Hint: index=0)\n",
    "trip_stop = itinerary[0]\n",
    "print(trip_stop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c09dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "city = trip_stop[\"City\"]\n",
    "country = trip_stop[\"Country\"]\n",
    "arrival = trip_stop[\"Arrival\"]\n",
    "departure = trip_stop[\"Departure\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6accb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"I will visit {city}, {country}, from {arrival} to {departure}. \n",
    "Please create a detailed daily itinerary.\"\"\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35b93ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the LLM response\n",
    "response = get_llm_response(prompt)\n",
    "\n",
    "# Print in Markdown format\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88074892",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_journal(file):\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "    print(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78566a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_journal(file):\n",
    "    f = open(file, \"r\")\n",
    "    journal = f.read()\n",
    "    f.close()\n",
    "    # print(journal)\n",
    "    return journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20c13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahrenheit_to_celsius(fahrenheit):\n",
    "    # Calculation for getting the temperature in celsius\n",
    "    celsius = (fahrenheit - 32) * 5 / 9\n",
    "    # Print the results\n",
    "    print(f\"{fahrenheit}Â°F is equivalent to {celsius:.2f}Â°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a1af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import get_llm_response\n",
    "\n",
    "def create_bullet_points(file):\n",
    "    # Complete code below to read in the file and store the contents as a string\n",
    "    f = open(file, \"r\")\n",
    "    file_contents = f.read()\n",
    "    f.close()\n",
    "    # Write a prompt and pass to an LLM\n",
    "    prompt = f\"\"\"create a three bullet point summary, and returns the bullets as a string. \n",
    "    In the following  file_contents:\n",
    "    {file_contents}\n",
    "    \"\"\"\n",
    "    bullets = get_llm_response(prompt) # Don't forget to add your prompt!\n",
    "\n",
    "    # Return the bullet points\n",
    "    return bullets\n",
    "\n",
    "# This line of code runs your function for istanbul.txt and returns the output\n",
    "output_bullets = create_bullet_points(\"istanbul.txt\")\n",
    "\n",
    "# Print the fucntion output\n",
    "print(output_bullets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file):\n",
    "    f = open(file, \"r\")\n",
    "    \n",
    "    csv_reader = csv.DictReader(f)\n",
    "    data = []\n",
    "    for row in csv_reader:\n",
    "        data.append(row)\n",
    "    f.close()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3609bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the itinerary.csv file\n",
    "itinerary = read_csv(\"itinerary.csv\")\n",
    "\n",
    "# Display the itinerary\n",
    "display_table(itinerary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b56d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The function called 'read_journal'\n",
    "def read_journal(journal_file):\n",
    "    f = open(journal_file, \"r\")\n",
    "    journal = f.read() \n",
    "    f.close()\n",
    "\n",
    "    # Return the journal content\n",
    "    return journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e768054b",
   "metadata": {},
   "outputs": [],
   "source": [
    "journal = read_journal(\"sydney.txt\")\n",
    "\n",
    "print(journal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88992152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the prompt\n",
    "prompt = f\"\"\"Please extract a comprehensive list of the restaurants \n",
    "and their respective specialties mentioned in the following journal entry. \n",
    "Ensure that each restaurant name is accurately identified and listed. \n",
    "Provide your answer in CSV format, ready to save. \n",
    "Exclude the \"```csv\" declaration, don't add spaces after the comma, include column headers.\n",
    "\n",
    "Format:\n",
    "Restaurant, Specialty\n",
    "Res_1, Sp_1\n",
    "...\n",
    "\n",
    "Journal entry:\n",
    "{journal}\n",
    "\"\"\"\n",
    "\n",
    "# Print the prompt\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b75bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the prompt\n",
    "prompt = f\"\"\"Please extract a comprehensive list of the restaurants \n",
    "and their respective specialties mentioned in the following journal entry. \n",
    "Ensure that each restaurant name is accurately identified and listed. \n",
    "Provide your answer in CSV format, ready to save. \n",
    "Exclude the \"```csv\" declaration, don't add spaces after the comma, include column headers.\n",
    "\n",
    "Format:\n",
    "Restaurant, Specialty\n",
    "Res_1, Sp_1\n",
    "...\n",
    "\n",
    "Journal entry:\n",
    "{journal}\n",
    "\"\"\"\n",
    "\n",
    "# Print the prompt\n",
    "print_llm_response(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "58d242d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fahrenheit_to_celsius(fahrenheit):\n",
    "    celsius= (fahrenheit-32)*5/9\n",
    "    print(f\"{fahrenheit}Â°F is equivalent to {celsius:.2f}Â°C\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "01eec89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64Â°F is equivalent to 17.78Â°C\n"
     ]
    }
   ],
   "source": [
    "fahrenheit_to_celsius(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f25d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
